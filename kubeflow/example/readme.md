# Example: Creating pipeline and inference service in Kubeflow

This folder contains all necessary files to reproduce an example where a pipeline is deployed.

## Introduction
The main objective of this pipeline is to perform the model training for a driving profile prediction problem. 

The pipeline is composed of the following components:

### Connecting to MinIO
First of all, it is necessary to connect with the [MinIO](https://minio.platform.flexigrobots-h2020.eu/) server. For this reason, the user has to introduce the identification credentials. For security reasons, these values are read from environment variables. Accordingly, an .env file has to be created inside the [example](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example) folder. The credentials values in the .env are: 

```bash
MINIO_ACCESS_KEY=USER_EXAMPLE
MINIO_SECRET_KEY=PASSWORD_EXAMPLE
```

### Downloading data
This component implements the necessary logic to download the dataset, that will feed the model, from FlexiGroBots' [MinIO](https://minio.platform.flexigrobots-h2020.eu/).

The dataset contains 7 columns and 330 rows generated by a simulator:
* Each row corresponds to a different vehicle.
* First column contains each vehicle id.
* Five columns corresponds to measurements from vehicle sensors (mean_acceleration, mean_fuel, mean_speed, duration, route_length) that will be used to categorize the driving profile.
* Last column corresponds to the target, the driving profile associated to a group of measurements, from 0 to 3.

### Preprocessing data:
This component performs the dataset splitting into training and test sets before feeding the model. The splitting schema is 80% for training and 20% for testing.

### Model training:
In this component, it is defined the machine learning model, developed with Keras framework and composed of:
* A first dense layer with a dimensionality of 16 units.
* One dropout layer with a 10% of units to drop.
* A final dense layer with softmax as activation function. 

The model training is performed over 10 epochs and it return the accuracy as main evaluation metric.

After training, the model is stored in the FlexiGroBots' MinIO.

## Steps to deploy a pipeline

### Developing the logic of each component 
The first step to deploy a pipeline is to develop the logic of all component that build this pipeline. In this example, the pipeline is composed by three components, so, it is needed to code three diferent Python files for each one. These scripts are: [downloading data](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/Download_data/download_data.py), [preprocessing data](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/Preprocess_data/preprocess_data.py) and [model training](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/Train_model/train_model.py).

### Specifying requirements
Before creating a container from these Python files, it is mandatory to freeze the necessary libraries as requirements to install. In [downloading libraries](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/Download_data/requirements.txt), [preprocessing libraries](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/Preprocess_data/requirements.txt) and [training libraries](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/Train_model/requirements.txt) it can be observed the most important libraries to take into account and its version.

### Dockerizing

#### Dockerfiles
Once logic and requirements files are ready, it is the moment to develop three different, but similar, Dockerfiles which allow to create three containers from the initial Python files, installing all necessary libraries. Next files contains all commands to create the containers: [downloading Dockerfile](/kubeflow/example/Download_data/Dockerfile), [preprocessing Dockerfile](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/Preprocess_data/Dockerfile) and [training Dockerfile](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/examplehttps://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/Train_model/Dockerfile).

#### Building and pushing the container
After coding the Dockerfile, it is necessary to build each image and to push it to a remote repository where it can be accessible to use.

Executing from the Dockerfile folder:

```bash
docker build -t <image_name> .
```

```bash
docker tag <image_name> <remote_repo_name>/<image_name>
```

```bash
docker push <remote_repo_name>/<image_name>
```

### Using docker images
These three docker images, that have been generated in previous steps, will be used in different .yaml files as the containers of the desired implementation. This procedure can be found in: [downloading yaml file](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/Download_data/download_data.yaml), [preprocessing yaml file](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/preprocess_data/preprocess_data.yaml) and [training yaml file](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/train_model/train_model.yaml).

### Defining and creating the pipeline
Once all .yaml files are ready, each of them will be used to define each development as a Kubeflow component. The code that explain this definition process can be found in [the main notebook](https://github.com/FlexiGroBots-H2020/AI-platform/tree/master/kubeflow/example/demo-notebook.ipynb) of the example, specifically, in the "Define Kubeflow Pipeline and then create service" paragraph.

To run this Jupyter notebook inside a Kubeflow workspace, firstly, users have to create a new Kubeflow notebook (if there is no one created yet):

![](/kubeflow/example/pics/New_notebook.PNG)


When creating this Kubeflow notebook, users have to specify the name for this notebook and what kind of image the notebook will use.
If needed, GPU resources must also be explicitly determined.

Note: it has been noted that a sufficient amount of memory (at least 4Gi) must be
provisioned to avoid Jupyter's kernel restarts when using CUDA. It is also
recommended to increase the default "Requested CPUs" value.

![](/kubeflow/example/pics/Notebook_details.PNG)

Once the Kubeflow notebook is ready, users can connect to it and upload the Jupyter notebook and all yaml files by clicking on the "Upload Files" button:

![](/kubeflow/example/pics/Upload.PNG)

It is also possible to clone the repository containing the example (https://github.com/FlexiGroBots-H2020/AI-platform.git) as shown in the following screenshot:

![](/kubeflow/example/pics/Clone.PNG)

Then, you will find the example code in the following directory:

```
~/AI-platform/kubeflow/example
```

### Uploading pipeline
After creating the pipeline, it has to be uploaded to Kubeflow before running. In the paragraph "Upload pipeline" of [the main notebook](/kubeflow/example/demo-notebook.ipynb) can be found this process.

It is important to change the name of the pipeline in this piece of code because, it is not allowed two pipelines with the same name.
In the example, this issue is solved by random name generation,
but you can always choose one you like best.

### Running pipeline
The last step of a Kubeflow service deployment consists on running the pipeline that has been created after uploading it.

To execute the pipeline, users have to go to "Pipelines" menu inside Kubeflow:
 
 ![](/kubeflow/example/pics/Pipelines.PNG)
 
 After that, click on the pipeline that has been uploaded and click on "Create run".
 
![](/kubeflow/example/pics/Create_run.PNG)
 
 In the "Start a run" view, it is mandatory to choose, or create, some related experiment to this run.

 ![](/kubeflow/example/pics/Experiment.PNG)

Finally, going to "Run" menu inside Kubeflow, the status of the pipeline deployment can be checked.

 ![](/kubeflow/example/pics/Run.PNG)

